{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bishalpaudel/BankApp/blob/master/sentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3XiUu7F5Eex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz2pOSU4v5yo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2f5b0b13-f4fc-4bb9-a22c-47d348b95217"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KWnghw5wPsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(\"/content/drive/My Drive/AI/SentimentAnalysis/Train_short_20k.tsv\", delimiter=\"\\t\")\n",
        "# df_test = pd.read_csv(\"/content/drive/My Drive/AI/SentimentAnalysis/test.tsv\", delimiter=\"\\t\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUICyoAi5k9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_train = df_train['Phrase']\n",
        "label_train = df_train['Sentiment']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hfbqRhV6sTg",
        "colab_type": "text"
      },
      "source": [
        "**2) Data Processing — convert to lower case**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH3C98_i6K4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_train = review_train.str.lower()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSzE4i7q7QOv",
        "colab_type": "text"
      },
      "source": [
        "**3) Data Processing — remove punctuation**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQA-I2ug7mdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "reviews_split = review_train.str.replace('[{}]'.format(string.punctuation), '')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ca24QqP98kq",
        "colab_type": "text"
      },
      "source": [
        "**5) Tokenize — Create Vocab to Int mapping dictionary**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAlWiLiE-N24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "all_text2 = ' '.join(reviews_split);\n",
        "\n",
        "# Creates a list of words\n",
        "words = all_text2.split()\n",
        "\n",
        "# Make a word count list\n",
        "count_words = Counter(words)\n",
        "\n",
        "total_words = len(words)\n",
        "\n",
        "# Get the most used words\n",
        "sorted_words = count_words.most_common(total_words)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO-WJ9CtpfC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Why i + 1: In order to start from 1 index, and not 0.\n",
        "# Integer Encoding:\n",
        "vocab_to_int = {w:i+1 for i, (w, c) in enumerate(sorted_words)}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKkz4CssqaNo",
        "colab_type": "text"
      },
      "source": [
        "**6) Tokenize — Encode the words:** Convert all the review text to integer based on integer-words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9bkZPObqpu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_int = []\n",
        "for review in reviews_split:\n",
        "  r = [vocab_to_int[w] for w in review.split()]\n",
        "  reviews_int.append(r)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJpkcA1ftjL0",
        "colab_type": "text"
      },
      "source": [
        "**7) Tokenize — Encode the labels**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9P4bz3qrD7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "encoded_labels = [1 if label>1 else 0 for label in label_train]\n",
        "encoded_labels = np.array(encoded_labels)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-x1QEoctckS",
        "colab_type": "text"
      },
      "source": [
        "**8) Analyze Reviews Length**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCy-yjqotfhw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "2903fdfe-c2b2-4ad4-e45d-bf3151b7217a"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "reviews_len = [len(x) for x in reviews_int]\n",
        "pd.Series(reviews_len).hist()\n",
        "plt.show()\n",
        "\n",
        "pd.Series(reviews_len).describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    19999.000000\n",
              "mean         5.819891\n",
              "std          6.358711\n",
              "min          0.000000\n",
              "25%          2.000000\n",
              "50%          3.000000\n",
              "75%          8.000000\n",
              "max         46.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMOVBJHBunix",
        "colab_type": "text"
      },
      "source": [
        "**9) Removing Outliers — Getting rid of extremely long or short reviews**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efgZWkOzuuW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_int = [reviews_int[i] for i, l in enumerate(reviews_len) if l > 0]\n",
        "encoded_labels = [encoded_labels[i] for i, l in enumerate(reviews_len) if l > 0]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAb1B5gMg5q0",
        "colab_type": "text"
      },
      "source": [
        "**10) Padding / Truncating the remaining data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrt6qLIug5Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_features(reviews_int, seq_length):\n",
        "  features = np.zeros((len(reviews_int), seq_length), dtype=int)\n",
        "\n",
        "  for i, review in enumerate(reviews_int):\n",
        "    review_len = len(review)\n",
        "\n",
        "    # Pad with Zeros\n",
        "    if review_len < seq_length:\n",
        "      zeros = list(np.zeros(seq_length - review_len))\n",
        "      new = zeros + review\n",
        "    # Truncate\n",
        "    elif reviews_len > seq_length:\n",
        "      new = review[0:seq_length]\n",
        "\n",
        "    features[i,:] = np.array(new)\n",
        "  return features\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDo4FhfRjLD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = pad_features(reviews_int, 200)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4309iJEkU-E",
        "colab_type": "text"
      },
      "source": [
        "**11) Training, Validation, Test Dataset Split**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_4yJkRdkUvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_frac = 0.8\n",
        "len_feat = len(features)\n",
        "train_x = features[0 : int(split_frac * len_feat)]\n",
        "train_y = encoded_labels[0 : int(split_frac * len_feat)]\n",
        "\n",
        "remaining_x = features[int(split_frac * len_feat) : ]\n",
        "remaining_y = encoded_labels[int(split_frac * len_feat) : ]\n",
        " \n",
        "valid_x = remaining_x[0 : int(len(remaining_x) * 0.5)]\n",
        "valid_y = remaining_y[0 : int(len(remaining_y) * 0.5)]\n",
        "\n",
        "test_x = remaining_x[int(len(remaining_x) * 0.5) : ]\n",
        "test_y = remaining_y[int(len(remaining_y) * 0.5) : ]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E3GnQjvyryD",
        "colab_type": "text"
      },
      "source": [
        "**12) Dataloaders and Batching**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7dLyoZgw5z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(np.asarray(train_x)), torch.from_numpy(np.asarray(train_y)))\n",
        "valid_data = TensorDataset(torch.from_numpy(np.asarray(valid_x)), torch.from_numpy(np.asarray(valid_y)))\n",
        "test_data = TensorDataset(torch.from_numpy(np.asarray(test_x)), torch.from_numpy(np.asarray(test_y)))\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle = True, batch_size = batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle = True, batch_size = batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle = True, batch_size = batch_size)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1092ihQyvIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7c5e1da6-6a95-4d2e-c9c7-9cc78423802b"
      },
      "source": [
        "train_on_gpu = False\n",
        "data_iter = iter(train_loader)\n",
        "sample_x, sample_y = data_iter.next()\n",
        "\n",
        "\n",
        "print('sample input size: ', sample_x.size())\n",
        "print('sample input \\n', sample_x)\n",
        "print()\n",
        "print('sample label size: ', sample_y.size())\n",
        "print('sample label \\n', sample_y)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample input size:  torch.Size([50, 200])\n",
            "sample input \n",
            " tensor([[   0,    0,    0,  ...,    8,  436,  164],\n",
            "        [   0,    0,    0,  ...,    0,    1,   75],\n",
            "        [   0,    0,    0,  ...,   75,  769, 3230],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ...,    2,  960,  343],\n",
            "        [   0,    0,    0,  ...,   13,  169, 1179],\n",
            "        [   0,    0,    0,  ...,    8, 1025,  284]])\n",
            "\n",
            "sample label size:  torch.Size([50])\n",
            "sample label \n",
            " tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
            "        1, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WiBsGh5ZVd_",
        "colab_type": "text"
      },
      "source": [
        "**14) Define the Model Class**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip8kExC8ZVGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentLSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "    super().__init__()\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    # Passing x though embedding layer\n",
        "    embeds = self.embedding(x)\n",
        "\n",
        "    # Passing x though LSTM layer\n",
        "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "    # Stack up LSTM outputs\n",
        "    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "    # Passing output though dropout layer: in order to regularize\n",
        "    out = self.dropout(lstm_out)\n",
        "\n",
        "    # Passing x though fully connected layer, in order to reduce dimension to linear\n",
        "    out = self.fc(out)\n",
        "\n",
        "    # Passing fully connected output through sigmoid in order to contain output between 0 and 1\n",
        "    sig_out = self.sig(out)\n",
        "\n",
        "    sig_out = sig_out.view(batch_size, -1)\n",
        "    sig_out = sig_out[:, -1]\n",
        "\n",
        "    return sig_out, hidden\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    ''' Initializes hidden state '''\n",
        "    weight = next(self.parameters()).data\n",
        "\n",
        "    if (train_on_gpu):\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "    else:\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "      \n",
        "    return hidden\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dyT16ltfp7-",
        "colab_type": "text"
      },
      "source": [
        "**15) Training the Network**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UjzTpOdf3Rm",
        "colab_type": "text"
      },
      "source": [
        "- **Instantiate the network**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqUl5O6Wfrqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "30854f39-9019-4cdd-c0a4-300e329f37a4"
      },
      "source": [
        "# +1 for 0 padding\n",
        "vocab_size = len(vocab_to_int) + 1\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "print(net)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(4455, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dj-Ol6AhM2S",
        "colab_type": "text"
      },
      "source": [
        "- **Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Soz1I3iyhRGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "epochs = 4\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip = 5\n",
        "\n",
        "if (train_on_gpu):\n",
        "  net.cuda()\n",
        "\n",
        "net.train()\n",
        "\n",
        "for e in range(epochs):\n",
        "  # Initialize hidden state\n",
        "  h = net.init_hidden(batch_size)\n",
        "\n",
        "  for inputs, labels in train_loader:\n",
        "    print(counter);\n",
        "    counter += 1;\n",
        "    if (inputs.size()[0] != 50):\n",
        "      continue\n",
        "\n",
        "    if train_on_gpu:\n",
        "      inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    net.zero_grad()\n",
        "\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "    output, h = net(inputs, h)\n",
        "\n",
        "    # Calculate the loss and perform backprop\n",
        "    loss = criterion(output.squeeze(), labels.float())\n",
        "    loss.backward()\n",
        "\n",
        "    # `clip_grad_norm` helps prevent exploding gradient problem in RNNs/LSTMs\n",
        "    nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    if counter % print_every == 0:\n",
        "      # Get validation loss\n",
        "      val_h = net.init_hidden(batch_size)\n",
        "      val_losses = []\n",
        "      net.eval()\n",
        "\n",
        "      for inputs_v, labels_v in valid_loader:\n",
        "        if (inputs_v.size()[0] != 50):\n",
        "          continue\n",
        "\n",
        "        val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "        # if (train_on_gpu):\n",
        "        #   inputs_v, labels = inputs_v.cuda(), labels_v.cuda()\n",
        "\n",
        "        # print('inputs_v.size()')\n",
        "        # print(inputs_v.size()[0])\n",
        "        # print('inputs_v.size()[0] == 50')\n",
        "        # print(inputs_v.size()[0] == 50)\n",
        "        # print('val_h.count')\n",
        "        # print(val_h.count)\n",
        "        \n",
        "        inputs_v = inputs_v.type(torch.LongTensor)\n",
        "        output_valid, val_h = net(inputs_v, val_h)\n",
        "\n",
        "        val_loss = criterion(output_valid.squeeze(), labels_v.float())\n",
        "\n",
        "        val_losses.append(val_loss.item())\n",
        "      \n",
        "      net.train()\n",
        "      print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "            \"Step: {}...\".format(counter),\n",
        "            \"Loss: {:.6f}\".format(loss.item()),\n",
        "            \"Val loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDT7l70Et97i",
        "colab_type": "text"
      },
      "source": [
        "**16) Testing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9OmYRzxuAzf",
        "colab_type": "text"
      },
      "source": [
        "- **On Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VA5RiYIuKNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "007d0bc1-a2d5-4260-d075-d33351fe84e1"
      },
      "source": [
        "test_losses = []\n",
        "num_correct = 0\n",
        "\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "  if (inputs.size()[0] != 50):\n",
        "    continue\n",
        "  h = tuple([each.data for each in h])\n",
        "\n",
        "  if(train_on_gpu):\n",
        "    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "  inputs = inputs.type(torch.LongTensor)\n",
        "  output, h = net(inputs, h)\n",
        "\n",
        "  test_loss = criterion(output.squeeze(), labels.float())\n",
        "  test_losses.append(test_loss.item())\n",
        "\n",
        "  # Convert output probabilities to predicted class (0 or 1)\n",
        "  pred = torch.round(output.squeeze())\n",
        "\n",
        "  # Compare predictions to true label\n",
        "  correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "  correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "  num_correct += np.sum(correct)\n",
        "\n",
        "# Average test loss\n",
        "print(\"Test Loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# Accuracy over all test data\n",
        "test_acc = num_correct / len(test_loader.dataset)\n",
        "print(\"Test Accuracy: {:.3f}\".format(test_acc))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.521\n",
            "Test Accuracy: 0.787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSa3EvRx6eYQ",
        "colab_type": "text"
      },
      "source": [
        "- **On User-generated Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7wTCOLe6drF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f4b2d6f7-e7df-49d7-b737-064547984faa"
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_review(test_review):\n",
        "    test_review = test_review.lower() # lowercase\n",
        "    # get rid of punctuation\n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "\n",
        "    # splitting by spaces\n",
        "    test_words = test_text.split()\n",
        "\n",
        "    # tokens\n",
        "    test_ints = []\n",
        "    test_ints.append([vocab_to_int[word] for word in test_words])\n",
        "\n",
        "    return test_ints\n",
        "\n",
        "# test_review_neg = 'I hate this movie.'\n",
        "# # test code and generate tokenized review\n",
        "# test_ints = tokenize_review(test_review_neg)\n",
        "# print(test_ints)\n",
        "\n",
        "\n",
        "# test sequence padding\n",
        "seq_length=200\n",
        "features = pad_features(test_ints, seq_length)\n",
        "\n",
        "print(features)\n",
        "\n",
        "\n",
        "# test conversion to tensor and pass into your model\n",
        "feature_tensor = torch.from_numpy(features)\n",
        "print(feature_tensor.size())\n",
        "\n",
        "\n",
        "def predict(net, test_review, sequence_length=200):\n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    # tokenize review\n",
        "    test_ints = tokenize_review(test_review)\n",
        "    \n",
        "    # pad tokenized sequence\n",
        "    seq_length=sequence_length\n",
        "    features = pad_features(test_ints, seq_length)\n",
        "    \n",
        "    # convert to tensor to pass into your model\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "    \n",
        "    batch_size = feature_tensor.size(0)\n",
        "    \n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        feature_tensor = feature_tensor.cuda()\n",
        "    \n",
        "    # get the output from the model\n",
        "    output, h = net(feature_tensor, h)\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze()) \n",
        "    # printing output value, before rounding\n",
        "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "    \n",
        "    # print custom response\n",
        "    if(pred.item()==1):\n",
        "        print(\"Positive review detected!\")\n",
        "    else:\n",
        "        print(\"Negative review detected.\")\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    46 3562   19   16]]\n",
            "torch.Size([1, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjy-g-DPFs8b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "48494a66-7a83-47f9-fd0b-02abc8654bc1"
      },
      "source": [
        "test_review_neg = 'This movie had the best acting and the dialogue was so good. I loved it.'\n",
        "seq_length=200 # good to use the length that was trained on\n",
        "predict(net, test_review_neg, seq_length)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction value, pre-rounding: 0.774283\n",
            "Positive review detected!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}